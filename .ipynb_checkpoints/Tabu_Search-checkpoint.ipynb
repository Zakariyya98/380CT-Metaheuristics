{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabu Search\n",
    "\n",
    "We will be implementing our second meta-heuristic algorithm for the Travelling Salesman Problem (TSP) called Tabu Search. This algorithm is memory-based and is an iterative approach to the problem which works by removing components and marking them as Tabu as it iterates over the solution thus creating a neighbourhood which is restricted to only use non-tabu components.\n",
    "\n",
    "\n",
    "\n",
    "Pseudocode: (Tabu Search)\n",
    "\n",
    "Algorithm - Tabu Search\n",
    "Input: TabuList Size\n",
    "Output: Sbest (Shortest cycle path)\n",
    "\n",
    "\n",
    "1.  TabuList = ∅\n",
    "2.  while (stopCondition())\n",
    "3.    candidateList ← ∅\n",
    "4.    for (Scandidate ∈ Sbestneighbourhood)\n",
    "5.     if (containsAnyFeatures(Scandidate, TabuList))\n",
    "6.       candidateList ← Scandidate\n",
    "7.     end if\n",
    "8.  end while\n",
    "9.  Scandidate ← LocateBestCandidate(candidateList)\n",
    "10. if(Cost(Scandidate)≤ Cost(Sbest))\n",
    "11.  Sbest ← Scandidate\n",
    "12.  TabuList ← FeatureDifferences(Scandidate, Sbest)\n",
    "13.  while(TabuList > TabuListsize)\n",
    "14.    DeleteFeature(TabuList)\n",
    "15.  end while\n",
    "16. end if\n",
    "17. Return (Sbest)\n",
    "\n",
    "(Brownlee, 2015)\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "http://www.cleveralgorithms.com/nature-inspired/stochastic/tabu_search.html (Accessed 26th March 2020)\n",
    "\n",
    "\n",
    "Big O-Notation:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabu Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as graphs\n",
    "import random\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "\n",
    "class WeightedGraph:\n",
    "    n = 0\n",
    "    p = 0\n",
    "    low_weight = 0\n",
    "    up_weight = 0\n",
    "    distmatrix = {}\n",
    "    w_edges = []\n",
    "    def __init__(self,n,p,low_weight,up_weight):\n",
    "        \"\"\"\n",
    "        Variable n: number of nodes\n",
    "        Variable p: The probability of two nodes becoming connected\n",
    "        low/up weight: Possible weight values\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        self.p = p\n",
    "        self.low_weight= low_weight\n",
    "        self.up_weight = up_weight\n",
    "        \n",
    "    def RandomWGraph(self):\n",
    "        g = graphs.gnp_random_graph(self.n,self.p)\n",
    "        m = g.number_of_edges()\n",
    "        weights = [random.randint(self.low_weight, self.up_weight) for r in range(m)]\n",
    "        #unweighted connections\n",
    "        uw_edges = g.edges()\n",
    "        # Create weighted graph edge list\n",
    "        i=0\n",
    "        w_edges = []\n",
    "        ret_graph = graphs.Graph()\n",
    "        for edge in uw_edges:\n",
    "        #w_edges = [uw_edges[i][0], uw_edges[i][1], weights[i]]\n",
    "        #w_edges+={(edge[0],edge[1]):weights[i]}\n",
    "            ret_graph.add_edge(edge[0],edge[1],weight=weights[i])\n",
    "            i =i +1\n",
    "        #print(w_edges)\n",
    "        #return graphs.Graph(w_edges, weighted = True,s=weights)\n",
    "        return ret_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphdata(nodes, probability, min_weight, max_weight):\n",
    "    linkset = []\n",
    "    links = {}\n",
    "\n",
    "    if min_weight>max_weight:\n",
    "        print('Lower weight cannot be greater then upper weight for the weight range. ')\n",
    "        sys.exit()\n",
    "    if probability<0 or probability>1:\n",
    "        print('Probability incorrect. Must be between 0 and 1. ')\n",
    "        sys.exit()\n",
    "    generated_data = WeightedGraph(nodes, probability, min_weight, max_weight)\n",
    "    generated = generated_data.RandomWGraph()\n",
    "    node_list=list(generated.nodes())\n",
    "    weight_of_all_nodes=0\n",
    "    for a in node_list:\n",
    "        for b in node_list:\n",
    "            if a==b:\n",
    "                continue\n",
    "            link = []\n",
    "            link.append(a)\n",
    "            link.append(b)\n",
    "            weight_of_edge=generated.get_edge_data(a,b)['weight']\n",
    "            link.append(weight_of_edge)\n",
    "            linkset.append(link)\n",
    "            print('%d %d %d' % (a,b,weight_of_edge))\n",
    "            if weight_of_edge>weight_of_all_nodes:\n",
    "                weight_of_all_nodes=weight_of_edge\n",
    "\n",
    "    for link in linkset:\n",
    "        try:\n",
    "            linklist = links[str(link[0])]\n",
    "            linklist.append(link[1:])\n",
    "            links[str(link[0])] = linklist\n",
    "        except:\n",
    "            links[str(link[0])] = [link[1:]]\n",
    "\n",
    "    return links, weight_of_all_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tabu_search(graph, max_weight):\n",
    "    global max_fitness, start_node\n",
    "    \n",
    "\n",
    "    ## Below, get the keys (node names) and shuffle them, and make start_node as start\n",
    "    s0 = list(graph.keys())\n",
    "    shuffle(s0)\n",
    "\n",
    "    if int(s0[0]) != start_node:\n",
    "        for i in range(len(s0)):\n",
    "            if  int(s0[i]) == start_node:\n",
    "                swap = s0[0]\n",
    "                s0[0] = s0[i]\n",
    "                s0[i] = swap\n",
    "                break;\n",
    "\n",
    "    # max_fitness will act like infinite fitness\n",
    "    max_fitness = ((max_weight) * (len(s0)))+1\n",
    "    sBest = s0\n",
    "    vBest = (s0, graph)\n",
    "    bestCandidate = s0\n",
    "    tabuList = []\n",
    "    tabuList.append(s0)\n",
    "    stop = False\n",
    "    best_keep_turn = 0\n",
    "\n",
    "\n",
    "    while not stop :\n",
    "        sNeighborhood = (bestCandidate)\n",
    "        bestCandidate = sNeighborhood[0]\n",
    "        for sCandidate in sNeighborhood:\n",
    "            if (sCandidate not in tabuList) and (((sCandidate, graph) < (bestCandidate, graph))):\n",
    "                bestCandidate = sCandidate\n",
    "\n",
    "\n",
    "        tabuList.append(bestCandidate)\n",
    "        if (len(tabuList) > maxTabuSize):\n",
    "            tabuList.pop(0)\n",
    "\n",
    "        if best_keep_turn == stoppingTurn:\n",
    "            stop = True\n",
    "\n",
    "        best_keep_turn += 1\n",
    "\n",
    "   \n",
    "    return sBest, vBest\n",
    "\n",
    "\n",
    "\n",
    "## Tabu Search Takes edge-list in a given format:\n",
    "#nodefrom nodeto weight\n",
    "#0 1 5\n",
    "#3 2 4\n",
    "#1 0 3\n",
    "#Undirectional edges should be written 2 times for both nodes.\n",
    "maxTabuSize = 10000\n",
    "neighborhood_size = 500\n",
    "stoppingTurn = 500\n",
    "max_fitness = 0\n",
    "start_node = 0\n",
    "graph, max_weight = graphdata(nodes=5, probability=1, min_weight=1, max_weight=100)\n",
    "solution, value = tabu_search(graph, max_weight)\n",
    "\n",
    "print(solution)\n",
    "print('----> '.join(a for a in solution))\n",
    "print('Shortest Distance Below:')\n",
    "print(value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnts_n = []\n",
    "pnts_t = []\n",
    "\n",
    "n = 3\n",
    "t0 = t1 = 0\n",
    "\n",
    "while t1-t0<0.1:\n",
    "    graph, max_weight = graphdata(n, probability=1, min_weight=1, max_weight=100)\n",
    "    t0 = time()\n",
    "    tabu_search(graph, max_weight)\n",
    "    t1 = time ()\n",
    "    # record time\n",
    "    print( f\"{n}\\t{t1-t0}\" )\n",
    "    pnts_n.append( n )\n",
    "    pnts_t.append( t1-t0)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine size of the graph\n",
    "plt.rcParams[\"figure.figsize\"] = (6,5)\n",
    "# Plot data\n",
    "plt.plot(pnts_n, pnts_t, 'ro-')\n",
    "# Label x and y axis\n",
    "plt.ylabel('time')\n",
    "plt.xlabel('cities (n)')\n",
    "# show graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "Graph Generation\n",
    "https://gist.github.com/RobertTalbert/9f0879e5ed4b4297fc5f\n",
    "\n",
    "Tabu Search Algorithm/GraphData\n",
    "https://github.com/polatbilek/Tabu-search-on-Travelling-Salesman-Problem/blob/master/tabu_search.py \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
